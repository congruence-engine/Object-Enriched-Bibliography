## Chapter 18: Image Captions and Alt-Text

**Figure 1**
*Caption:* Vector space representation of embeddings for full-text journal articles, shown alongside embeddings created using descriptions of museum objects from the Science Museum Group. Embeddings were generated using OpenAI’s text-embedding-3-large model; the graph was produced in Python with Matplotlib.

*Alt-Text:* 3D scatter plot showing the vector space positions of embeddings for full-text journal articles and descriptions of museum objects. Articles, shown as light grey triangles, form a tight cluster in the lower left corner, while objects, shown as black dots, are dispersed widely across the upper and right regions of the plot. This illustrates that the articles’ embeddings are more similar to each other and distinct from the more varied embeddings of the objects. Axes are labelled x, y, and z, with a legend identifying the two categories.

**Figure 2**
*Caption:* Vector space representation of embeddings for named entity recognition (NER) ‘object’ terms detected by GLiNER in the article “Political Economy and the Medici” by Sophus A. Reinert and Robert Fredona, shown alongside embeddings created using descriptions of museum objects from the Science Museum Group. Embeddings were generated using the open-source model sentence-transformers/all-MiniLM-L6-v2; the graph was produced in Python with Matplotlib.

*Alt-Text:* 3D scatter plot showing the vector space positions of embeddings for NER-detected terms and descriptions of museum objects. The NER terms, shown as light grey triangles, form a cluster in one area, while the museum objects, shown as black dots, are dispersed across the graph. Notably, there are areas of significant overlap between the NER terms and the museum objects.


